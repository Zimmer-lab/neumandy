{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Data Diagnostics I </b> *✲ﾟ*｡✧٩(･ิᴗ･ิ๑)۶*✲ﾟ*｡✧\n",
    "\n",
    "In this notebook we will explore derivatives and see how our data changes. This helps smooth out data and can be the basis for future dynamical systems analysis.\n",
    "\n",
    "## Time Derivatives - Total Variation Regulzariation\n",
    "Since we are interested in the shape of our data and want to eliminate noise as much as possible, we will take the time derivative of our data. \n",
    "To this end we will use an iterative total variation regularization method to compute the first order derivative of our data. Finite difference methods estimate derivatibes by looking at the changes in the values over small intervals dt. This time step size dt is the reciprocal of the sampling frequency which is 3 in our case.\n",
    "We will apply this on each dataset individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastest results\n",
    "resampled_derivatives = hf.compute_derivatives(quartiled_data, length_dict,1,0.01)\n",
    "resampled_derivatives.to_pickle(\"resampled_derivatives_It1_Gam01.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 2 and 10\n",
    "resampled_derivatives_It2= hf.compute_derivatives(quartiled_data, length_dict, 2, 0.01)\n",
    "resampled_derivatives_It5 = hf.compute_derivatives(quartiled_data, length_dict, 5, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 2 and gamma 0.001 and 10\n",
    "resampled_derivatives_Gam001 = hf.compute_derivatives(quartiled_data, length_dict, 2, 0.001)\n",
    "resampled_derivatives_Gam10 = hf.compute_derivatives(quartiled_data, length_dict, 2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_derivatives_Gam001[\"state\"] = truncated_dataframe[\"state\"]\n",
    "resampled_derivatives_Gam10[\"state\"] = truncated_dataframe[\"state\"]\n",
    "resampled_derivatives_It2[\"state\"] = truncated_dataframe[\"state\"]\n",
    "resampled_derivatives_It5[\"state\"] = truncated_dataframe[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib widget\n",
    "saving_path2=\"..\\\\plots\\\\23Jan\\\\totalvariation_plots\\\\Iteration2Gamma0.01\\\\\"\n",
    "saving_path5=\"..\\\\plots\\\\23Jan\\\\totalvariation_plots\\\\Iteration5Gamma0.01\\\\\"\n",
    "saving_path001=\"..\\\\plots\\\\23Jan\\\\totalvariation_plots\\\\Iteration2Gamma0.001\\\\\"\n",
    "saving_path10=\"..\\\\plots\\\\23Jan\\\\totalvariation_plots\\\\Iteration2Gamma0.1\\\\\"\n",
    "\n",
    "hf.plot_from_stacked_imputed(length_dict, resampled_derivatives_It2, resampled_derivatives_It2, saving_path2)\n",
    "hf.plot_from_stacked_imputed(length_dict, resampled_derivatives_It5, resampled_derivatives_It5, saving_path5)\n",
    "hf.plot_from_stacked_imputed(length_dict, resampled_derivatives_Gam001, resampled_derivatives_Gam001, saving_path001)\n",
    "hf.plot_from_stacked_imputed(length_dict, resampled_derivatives_Gam10, resampled_derivatives_Gam10, saving_path10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path2=\"..\\\\plots\\\\23Jan\\\\totalvariation_plots\\\\Iteration2Gamma0.01\\\\\"\n",
    "hf.plot_from_stacked_imputed(length_dict, resampled_derivatives_It2, resampled_derivatives_It2, saving_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best results: It 5, Gamma 0.01\n",
    "resampled_derivatives_595_It5_Gam01 = hf.compute_derivatives(quartiled_data.loc[:,quartiled_data.columns!=\"state\"], length_dict, 5, 0.01)\n",
    "resampled_derivatives_595_It5_Gam01[\"state\"] = quartiled_data[\"state\"]\n",
    "resampled_derivatives_595_It5_Gam01.to_pickle(\"resampled_derivatives_595_It5_Gam01.pkl\")\n",
    "# best results: It 5, Gamma 0.001\n",
    "resampled_derivatives_595_It5_Gam001 = hf.compute_derivatives(quartiled_data.loc[:,quartiled_data.columns!=\"state\"], length_dict, 5, 0.001)\n",
    "resampled_derivatives_595_It5_Gam001[\"state\"] = quartiled_data[\"state\"]\n",
    "resampled_derivatives_595_It5_Gam001.to_pickle(\"resampled_derivatives_595_It5_Gam001.pkl\")\n",
    "resampled_derivatives_595_It5_Gam001 = pd.read_pickle(\"resampled_derivatives_595_It5_Gam001.pkl\")\n",
    "saving_path5_1=\"..\\\\plots\\\\23Jan\\\\totalvariation_plots\\\\Iteration5Gamma0.001\\\\\"\n",
    "\n",
    "hf.plot_from_stacked_imputed(length_dict, resampled_derivatives_595_It5_Gam001, resampled_derivatives_595_It5_Gam001, saving_path5_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_derivatives_cumsum = resampled_derivatives.copy()\n",
    "\n",
    "dt = 1/3 # time step: 1/(frame rate)\n",
    "start_index = 0\n",
    "for dataset_idx in tqdm(range(len(dataframes.keys())), desc=\"Computing derivatives\"):\n",
    "    end_index = start_index + frames_num\n",
    "    integrated = np.cumsum(resampled_derivatives_cumsum[start_index:end_index])\n",
    "    resampled_derivatives_cumsum[start_index:end_index] = integrated + abs(integrated.min()) + 0.01 \n",
    "    start_index = end_index\n",
    "\n",
    "\n",
    "# plotting the trace of one neuron across all datasets\n",
    "# and save the plot\n",
    "fig, ax = plt.subplots(figsize=(40, 10))\n",
    "ax.plot(resampled_derivatives_cumsum['AVAR'].T, color=\"tab:blue\")\n",
    "ax.set_ylabel(\"AVAR\")\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_title(\"AVAR across all datasets\")\n",
    "fig.savefig(\"resampled_AVAR_alldatasets_It5.png\")\n",
    "pca = hf.PCA(n_components=3)\n",
    "temporal_PCs_totalvariation = pd.DataFrame(pca.fit_transform(resampled_derivatives_cumsum))\n",
    "%matplotlib widget\n",
    "window_size = 10\n",
    "\n",
    "# Applyin a 10-sample sliding average for smoother visualizations!\n",
    "temporal_PCs_totalvariation[0] = np.convolve(temporal_PCs_totalvariation[0], np.ones(window_size)/window_size, mode='same')\n",
    "temporal_PCs_totalvariation[1] = np.convolve(temporal_PCs_totalvariation[1], np.ones(window_size)/window_size, mode='same')\n",
    "temporal_PCs_totalvariation[2] = np.convolve(temporal_PCs_totalvariation[2], np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "temporal_PCs_totalvariation['state'] = turn_vec.values\n",
    "hf.plot_PCs(temporal_PCs_totalvariation,temporal_PCs_totalvariation['state'],'PCA_derivatives_totalvariation.html')\n",
    "hf.plot_PC_gif(temporal_PCs_totalvariation,temporal_PCs_totalvariation['state'],'PCA_totalvariation.gif')\n",
    "pca = hf.PCA(n_components=3)\n",
    "temporal_PCs_totalvariation = pd.DataFrame(pca.fit_transform(resampled_derivatives_It2_cumsum))\n",
    "\n",
    "# Applyin a 10-sample sliding average for smoother visualizations!\n",
    "temporal_PCs_totalvariation[0] = np.convolve(temporal_PCs_totalvariation[0], np.ones(window_size)/window_size, mode='same')\n",
    "temporal_PCs_totalvariation[1] = np.convolve(temporal_PCs_totalvariation[1], np.ones(window_size)/window_size, mode='same')\n",
    "temporal_PCs_totalvariation[2] = np.convolve(temporal_PCs_totalvariation[2], np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "temporal_PCs_totalvariation['state'] = turn_vec.values\n",
    "hf.plot_PCs(temporal_PCs_totalvariation,temporal_PCs_totalvariation['state'],'PCA_derivatives_totalvariation_It2.html')\n",
    "hf.plot_PC_gif(temporal_PCs_totalvariation,temporal_PCs_totalvariation['state'],'PCA_totalvariation_It2.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Butterworth Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butterworth_derivatives = quartiled_data.copy()\n",
    "dt = 1/3 # time step: 1/(frame rate)\n",
    "start_index = 0\n",
    "for dataset in dataframes.values():\n",
    "    end_index = start_index + frames_num\n",
    "    for col_index in range(len(butterworth_derivatives.columns)):\n",
    "        x_hat, dxdt_hat = pdiff.smooth_finite_difference.butterdiff(resampled_derivatives.iloc[start_index:end_index, col_index], dt, [3, 0.09], options={'iterate': False}) # x_hat: estimated (smoothed) x, dxdt_hat: estimated dx/dt, [1, 0.0001]: regularization parameters -> gamma=0.2 is too high, derivatives become too blocky\n",
    "        butterworth_derivatives.iloc[start_index:end_index, col_index] = dxdt_hat\n",
    "    #if end_index != len(resampled_derivatives):\n",
    "    #    resampled_derivatives.iloc[end_index, :] = np.nan #so that we have a separation between datasets   \n",
    "    start_index = end_index\n",
    "%%capture\n",
    "%matplotlib widget\n",
    "saving_path=\"C:\\\\Users\\\\LAK\\\\Documents\\\\butterworth_plots\\\\\"\n",
    "\n",
    "\n",
    "start_index = 0\n",
    "count = 0\n",
    "\n",
    "# we will unstack the dataframe and plot the traces for each dataset\n",
    "for obs_count in list(length_dict.values()):\n",
    "\n",
    "    # we take the number of observations from the length dictionary and add it to the start index\n",
    "    end_index = start_index + obs_count\n",
    "    res_data_df = butterworth_derivatives.iloc[start_index:end_index]\n",
    "\n",
    "    fig = hf.plot_traces.make_grid_plot_from_two_dataframes(\n",
    "            res_data_df, res_data_df)\n",
    "    # fig, ax = plot_traces.make_grid_plot_from_dataframe(df_imputed)\n",
    "\n",
    "    # save all plots in a folder\n",
    "    pathname = saving_path + list(length_dict.keys())[count] + \".png\"\n",
    "    fig.savefig(pathname)\n",
    "    plt.close(fig)\n",
    "    start_index = end_index\n",
    "    count += 1\n",
    "resampled_derivatives_butter_cumsum = resampled_derivatives.copy()\n",
    "\n",
    "dt = 1/3 # time step: 1/(frame rate)\n",
    "start_index = 0\n",
    "for dataset_idx in tqdm(range(len(dataframes.keys())), desc=\"Computing derivatives\"):\n",
    "    end_index = start_index + pts\n",
    "    integrated_bt = np.cumsum(butterworth_derivatives[start_index:end_index])\n",
    "    resampled_derivatives_butter_cumsum[start_index:end_index] = integrated_bt + abs(integrated_bt.min()) + 0.01\n",
    "\n",
    "    start_index = end_index\n",
    "pca = hf.PCA(n_components=3)\n",
    "pca_butterworth = pd.DataFrame(pca.fit_transform(resampled_derivatives_butter_cumsum))\n",
    "avg = pca_butterworth#.iloc[68595:72344]\n",
    "avg[\"state\"] = turn_vec.values#iloc[68595:72344].values\n",
    "\n",
    "avg[0] = np.convolve(avg[0], np.ones(window_size)/window_size, mode='same')\n",
    "avg[1] = np.convolve(avg[1], np.ones(window_size)/window_size, mode='same')\n",
    "avg[2] = np.convolve(avg[2], np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "hf.plot_PCs(avg,avg[\"state\"] ,'PCA_butterworth.html')\n",
    "hf.plot_PC_gif(avg,avg[\"state\"] ,'PCA_butterworth.gif')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
